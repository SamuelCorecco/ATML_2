{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alfiovavassori/Library/Mobile Documents/com~apple~CloudDocs/Documents/USI/Master/3rd Semester/Advanced Topics in Machine Learning/Project 2/ATML_2/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForMaskedLM,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    ")\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used Optuna for hyperparameter search\n",
    "def hp_space_optuna(trial):\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 5e-4, log=True),\n",
    "        \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 2, 5),\n",
    "        \"seed\": trial.suggest_categorical(\"seed\", [42, 1234, 2021]),\n",
    "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [8, 16, 32]),\n",
    "        \"per_device_eval_batch_size\": trial.suggest_categorical(\"per_device_eval_batch_size\", [8, 16, 32]),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.0, 0.1),\n",
    "    }\n",
    "\n",
    "def compute_objective(metrics):\n",
    "    \"\"\"\n",
    "    Objective function for hyperparameter search.\n",
    "    We want to minimize the validation loss. The Trainer by default returns 'eval_loss'.\n",
    "    \"\"\"\n",
    "    return metrics[\"eval_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {\n",
    "    'train': 'openassistant_best_replies_train.jsonl',\n",
    "    'test':  'openassistant_best_replies_eval.jsonl'\n",
    "}\n",
    "\n",
    "model_checkpoint = \"bert-base-uncased\"\n",
    "\n",
    "output_dir = \"./Models/Bert/v3/bert-finetuned-mlm\"\n",
    "\n",
    "default_num_train_epochs = 3\n",
    "default_train_batch_size = 8\n",
    "default_eval_batch_size = 8\n",
    "default_learning_rate = 5e-5\n",
    "default_weight_decay = 0.01\n",
    "seed = 42\n",
    "\n",
    "do_hpo = True  \n",
    "\n",
    "n_hpo_trials = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    set_seed(seed)\n",
    "    \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    print(\"Loading dataset from Hugging Face...\")\n",
    "    \n",
    "    train_data = pd.read_json(f\"hf://datasets/timdettmers/openassistant-guanaco/{splits['train']}\", lines=True)\n",
    "    test_data = pd.read_json(f\"hf://datasets/timdettmers/openassistant-guanaco/{splits['test']}\", lines=True)\n",
    "\n",
    "    train_dataset = Dataset.from_dict({\"text\": train_data[\"text\"].tolist()})\n",
    "    test_dataset = Dataset.from_dict({\"text\": test_data[\"text\"].tolist()})\n",
    "\n",
    "    print(f\"Number of training samples: {len(train_dataset)}\")\n",
    "    print(f\"Number of test samples:     {len(test_dataset)}\")\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(\n",
    "            examples[\"text\"],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=128\n",
    "        )\n",
    "\n",
    "    print(\"Tokenizing dataset...\")\n",
    "    train_tokenized = train_dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "    test_tokenized = test_dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    "    )\n",
    "\n",
    "    def model_init():\n",
    "        return AutoModelForMaskedLM.from_pretrained(model_checkpoint)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        overwrite_output_dir=True,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_steps=100,\n",
    "        num_train_epochs=default_num_train_epochs,\n",
    "        per_device_train_batch_size=default_train_batch_size,\n",
    "        per_device_eval_batch_size=default_eval_batch_size,\n",
    "        learning_rate=default_learning_rate,\n",
    "        weight_decay=default_weight_decay,\n",
    "        seed=seed,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model_init=model_init if do_hpo else None,  \n",
    "        model=None if do_hpo else AutoModelForMaskedLM.from_pretrained(model_checkpoint),\n",
    "        args=training_args,\n",
    "        train_dataset=train_tokenized,\n",
    "        eval_dataset=test_tokenized,\n",
    "        data_collator=data_collator,\n",
    "    )\n",
    "\n",
    "    if do_hpo:\n",
    "        print(\"\\n=== Running hyperparameter search ===\")\n",
    "        best_run = trainer.hyperparameter_search(\n",
    "            direction=\"minimize\",\n",
    "            hp_space=hp_space_optuna,\n",
    "            compute_objective=compute_objective,\n",
    "            n_trials=n_hpo_trials\n",
    "        )\n",
    "        print(\"Best hyperparameters found:\", best_run.hyperparameters)\n",
    "\n",
    "        for k, v in best_run.hyperparameters.items():\n",
    "            setattr(trainer.args, k, v)\n",
    "\n",
    "        trainer.model = trainer.model_init()\n",
    "    else:\n",
    "        print(\"Skipping hyperparameter search...\")\n",
    "\n",
    "    print(\"\\n=== Starting training ===\")\n",
    "    trainer.train()\n",
    "\n",
    "    print(\"\\n=== Evaluating on test dataset ===\")\n",
    "    eval_metrics = trainer.evaluate()\n",
    "    print(f\"Eval metrics: {eval_metrics}\")\n",
    "    if \"eval_loss\" in eval_metrics:\n",
    "        perplexity = torch.exp(torch.tensor(eval_metrics[\"eval_loss\"]))\n",
    "        print(f\"Perplexity: {perplexity.item():.2f}\")\n",
    "\n",
    "    print(f\"\\n=== Saving final model to {output_dir} ===\")\n",
    "    trainer.save_model(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    print(\"All done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2025-01-12 19:07:20\n",
      "Using device: cpu\n",
      "Loading dataset from Hugging Face...\n",
      "Number of training samples: 9846\n",
      "Number of test samples:     518\n",
      "Tokenizing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9846/9846 [00:01<00:00, 7028.89 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 518/518 [00:00<00:00, 7056.85 examples/s]\n",
      "/Users/alfiovavassori/Library/Mobile Documents/com~apple~CloudDocs/Documents/USI/Master/3rd Semester/Advanced Topics in Machine Learning/Project 2/ATML_2/.venv/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running hyperparameter search ===\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No hyperparameter search backend available.\n - To install optuna run `pip install optuna`\n - To install ray run `pip install 'ray[tune]'`\n - To install sigopt run `pip install sigopt`\n - To install wandb run `pip install wandb`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnd time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 64\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_hpo:\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== Running hyperparameter search ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 64\u001b[0m     best_run \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhyperparameter_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdirection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mminimize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhp_space\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhp_space_optuna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompute_objective\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_objective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_hpo_trials\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest hyperparameters found:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_run\u001b[38;5;241m.\u001b[39mhyperparameters)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m best_run\u001b[38;5;241m.\u001b[39mhyperparameters\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/USI/Master/3rd Semester/Advanced Topics in Machine Learning/Project 2/ATML_2/.venv/lib/python3.12/site-packages/transformers/trainer.py:3551\u001b[0m, in \u001b[0;36mTrainer.hyperparameter_search\u001b[0;34m(self, hp_space, compute_objective, n_trials, direction, backend, hp_name, **kwargs)\u001b[0m\n\u001b[1;32m   3496\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3497\u001b[0m \u001b[38;5;124;03mLaunch an hyperparameter search using `optuna` or `Ray Tune` or `SigOpt`. The optimized quantity is determined\u001b[39;00m\n\u001b[1;32m   3498\u001b[0m \u001b[38;5;124;03mby `compute_objective`, which defaults to a function returning the evaluation loss when no metric is provided,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3548\u001b[0m \u001b[38;5;124;03m    backend.\u001b[39;00m\n\u001b[1;32m   3549\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 3551\u001b[0m     backend \u001b[38;5;241m=\u001b[39m \u001b[43mdefault_hp_search_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3552\u001b[0m backend \u001b[38;5;241m=\u001b[39m HPSearchBackend(backend)\n\u001b[1;32m   3553\u001b[0m backend_obj \u001b[38;5;241m=\u001b[39m ALL_HYPERPARAMETER_SEARCH_BACKENDS[backend]()\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/USI/Master/3rd Semester/Advanced Topics in Machine Learning/Project 2/ATML_2/.venv/lib/python3.12/site-packages/transformers/hyperparameter_search.py:135\u001b[0m, in \u001b[0;36mdefault_hp_search_backend\u001b[0;34m()\u001b[0m\n\u001b[1;32m    131\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    132\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(available_backends)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m hyperparameter search backends available. Using \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as the default.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    133\u001b[0m         )\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m name\n\u001b[0;32m--> 135\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo hyperparameter search backend available.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - To install \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m run \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend\u001b[38;5;241m.\u001b[39mpip_install()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    139\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m backend \u001b[38;5;129;01min\u001b[39;00m ALL_HYPERPARAMETER_SEARCH_BACKENDS\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[1;32m    140\u001b[0m     )\n\u001b[1;32m    141\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No hyperparameter search backend available.\n - To install optuna run `pip install optuna`\n - To install ray run `pip install 'ray[tune]'`\n - To install sigopt run `pip install sigopt`\n - To install wandb run `pip install wandb`"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(f\"Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "    main()\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"End time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "    time_taken = end_time - start_time\n",
    "    print(f\"Time taken to execute the loop: {time_taken:.2f} seconds\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
