{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"collapsed_sections":["OvQqgdXMINpN","vF1d-My9IXXt","MHMmgcVwJdaT"]},"accelerator":"GPU","gpuClass":"standard","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10402552,"sourceType":"datasetVersion","datasetId":6445856},{"sourceId":10402860,"sourceType":"datasetVersion","datasetId":6446100}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Install Packages","metadata":{"id":"OvQqgdXMINpN"}},{"cell_type":"code","source":"!sudo apt install portaudio19-dev\n!pip3 install -U scipy\n!pip3 install wavio\n!pip3 install sounddevice\n\n!git clone https://github.com/jnordberg/tortoise-tts.git\n%cd tortoise-tts\n!pip3 install -r requirements.txt\n!pip3 install transformers==4.19.0 einops==0.5.0 rotary_embedding_torch==0.1.5 unidecode==1.3.5\n!python3 setup.py install\n\n\nimport torch\nimport torchaudio\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nimport IPython\n\nfrom tortoise.api import TextToSpeech\nfrom tortoise.utils.audio import load_audio, load_voice, load_voices\n\ntts = TextToSpeech()\n\nimport os\nfrom google.colab import files\n\nimport sounddevice as sd\nfrom scipy.io.wavfile import write\nimport wavio as wv\nimport time","metadata":{"id":"uC2qGJ0nITKW","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d03d1e15-91da-4ca6-ca62-2a1508877351","trusted":true,"execution":{"iopub.status.busy":"2025-01-08T13:18:13.903355Z","iopub.execute_input":"2025-01-08T13:18:13.903696Z","iopub.status.idle":"2025-01-08T13:20:27.942423Z","shell.execute_reply.started":"2025-01-08T13:18:13.903669Z","shell.execute_reply":"2025-01-08T13:20:27.941577Z"}},"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nThe following additional packages will be installed:\n  libportaudio2 libportaudiocpp0\nSuggested packages:\n  portaudio19-doc\nThe following NEW packages will be installed:\n  libportaudio2 libportaudiocpp0 portaudio19-dev\n0 upgraded, 3 newly installed, 0 to remove and 132 not upgraded.\nNeed to get 188 kB of archives.\nAfter this operation, 927 kB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudio2 amd64 19.6.0-1.1 [65.3 kB]\nGet:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudiocpp0 amd64 19.6.0-1.1 [16.1 kB]\nGet:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 portaudio19-dev amd64 19.6.0-1.1 [106 kB]\nFetched 188 kB in 0s (410 kB/s)          \u001b[0m\u001b[33m\ndebconf: unable to initialize frontend: Dialog\ndebconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\ndebconf: falling back to frontend: Readline\n\n\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package libportaudio2:amd64.\n(Reading database ... 127365 files and directories currently installed.)\nPreparing to unpack .../libportaudio2_19.6.0-1.1_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  8%]\u001b[49m\u001b[39m [####......................................................] \u001b8Unpacking libportaudio2:amd64 (19.6.0-1.1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 15%]\u001b[49m\u001b[39m [########..................................................] \u001b8Selecting previously unselected package libportaudiocpp0:amd64.\nPreparing to unpack .../libportaudiocpp0_19.6.0-1.1_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 23%]\u001b[49m\u001b[39m [#############.............................................] \u001b8Unpacking libportaudiocpp0:amd64 (19.6.0-1.1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 31%]\u001b[49m\u001b[39m [#################.........................................] \u001b8Selecting previously unselected package portaudio19-dev:amd64.\nPreparing to unpack .../portaudio19-dev_19.6.0-1.1_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 38%]\u001b[49m\u001b[39m [######################....................................] \u001b8Unpacking portaudio19-dev:amd64 (19.6.0-1.1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 46%]\u001b[49m\u001b[39m [##########################................................] \u001b8Setting up libportaudio2:amd64 (19.6.0-1.1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 54%]\u001b[49m\u001b[39m [###############################...........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 62%]\u001b[49m\u001b[39m [###################################.......................] \u001b8Setting up libportaudiocpp0:amd64 (19.6.0-1.1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 69%]\u001b[49m\u001b[39m [########################################..................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 77%]\u001b[49m\u001b[39m [############################################..............] \u001b8Setting up portaudio19-dev:amd64 (19.6.0-1.1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 85%]\u001b[49m\u001b[39m [#################################################.........] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 92%]\u001b[49m\u001b[39m [#####################################################.....] \u001b8Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n\n\n\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[JRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\nCollecting scipy\n  Downloading scipy-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.26.4)\nDownloading scipy-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.6 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m40.6/40.6 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: scipy\n  Attempting uninstall: scipy\n    Found existing installation: scipy 1.13.1\n    Uninstalling scipy-1.13.1:\n      Successfully uninstalled scipy-1.13.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.0 which is incompatible.\nydata-profiling 4.12.1 requires scipy<1.14,>=1.4.1, but you have scipy 1.15.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed scipy-1.15.0\nRequirement already satisfied: wavio in /usr/local/lib/python3.10/dist-packages (0.0.9)\nRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from wavio) (1.26.4)\nCollecting sounddevice\n  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\nRequirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice) (1.17.1)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice) (2.22)\nDownloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\nInstalling collected packages: sounddevice\nSuccessfully installed sounddevice-0.5.1\nCloning into 'tortoise-tts'...\nremote: Enumerating objects: 1481, done.\u001b[K\nremote: Total 1481 (delta 0), reused 0 (delta 0), pack-reused 1481 (from 1)\u001b[K\nReceiving objects: 100% (1481/1481), 53.56 MiB | 21.61 MiB/s, done.\nResolving deltas: 100% (604/604), done.\n/kaggle/working/tortoise-tts\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (4.66.5)\nCollecting rotary_embedding_torch (from -r requirements.txt (line 2))\n  Downloading rotary_embedding_torch-0.8.6-py3-none-any.whl.metadata (675 bytes)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (4.44.2)\nRequirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (0.19.1)\nRequirement already satisfied: inflect in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (7.4.0)\nCollecting progressbar (from -r requirements.txt (line 6))\n  Downloading progressbar-2.5.tar.gz (10 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (0.8.0)\nCollecting unidecode (from -r requirements.txt (line 8))\n  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (1.15.0)\nRequirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (0.10.2.post1)\nCollecting numba==0.48.0 (from -r requirements.txt (line 11))\n  Downloading numba-0.48.0.tar.gz (2.0 MB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting ffmpeg (from -r requirements.txt (line 12))\n  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting llvmlite<0.32.0,>=0.31.0dev0 (from numba==0.48.0->-r requirements.txt (line 11))\n  Downloading llvmlite-0.31.0.tar.gz (110 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from numba==0.48.0->-r requirements.txt (line 11)) (1.26.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba==0.48.0->-r requirements.txt (line 11)) (71.0.4)\nRequirement already satisfied: torch>=2.0 in /usr/local/lib/python3.10/dist-packages (from rotary_embedding_torch->-r requirements.txt (line 2)) (2.4.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 3)) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 3)) (0.24.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 3)) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 3)) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 3)) (2024.9.11)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 3)) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 3)) (0.4.5)\nRequirement already satisfied: more-itertools>=8.5.0 in /usr/local/lib/python3.10/dist-packages (from inflect->-r requirements.txt (line 5)) (10.5.0)\nRequirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from inflect->-r requirements.txt (line 5)) (4.3.0)\nRequirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 10)) (3.0.1)\nRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 10)) (1.2.2)\nRequirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 10)) (1.4.2)\nRequirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 10)) (4.4.2)\nINFO: pip is looking at multiple versions of librosa to determine which version is compatible with other requirements. This could take a while.\nCollecting librosa (from -r requirements.txt (line 10))\n  Downloading librosa-0.10.2-py3-none-any.whl.metadata (8.6 kB)\n  Downloading librosa-0.10.1-py3-none-any.whl.metadata (8.3 kB)\n  Downloading librosa-0.10.0.post2-py3-none-any.whl.metadata (8.3 kB)\n  Downloading librosa-0.10.0.post1-py3-none-any.whl.metadata (8.3 kB)\n  Downloading librosa-0.10.0-py3-none-any.whl.metadata (8.3 kB)\n  Downloading librosa-0.9.2-py3-none-any.whl.metadata (8.2 kB)\nCollecting resampy>=0.2.2 (from librosa->-r requirements.txt (line 10))\n  Downloading resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 10)) (0.12.1)\nRequirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 10)) (1.8.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers->-r requirements.txt (line 3)) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers->-r requirements.txt (line 3)) (4.12.2)\nRequirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa->-r requirements.txt (line 10)) (4.3.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (2024.8.30)\nINFO: pip is looking at multiple versions of resampy to determine which version is compatible with other requirements. This could take a while.\n  Downloading resampy-0.4.2-py3-none-any.whl.metadata (2.8 kB)\n  Downloading resampy-0.4.1-py3-none-any.whl.metadata (2.8 kB)\n  Downloading resampy-0.4.0-py3-none-any.whl.metadata (2.8 kB)\n  Downloading resampy-0.3.1-py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa->-r requirements.txt (line 10)) (3.5.0)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.10.2->librosa->-r requirements.txt (line 10)) (1.17.1)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->rotary_embedding_torch->-r requirements.txt (line 2)) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->rotary_embedding_torch->-r requirements.txt (line 2)) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->rotary_embedding_torch->-r requirements.txt (line 2)) (3.1.4)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa->-r requirements.txt (line 10)) (2.22)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0->rotary_embedding_torch->-r requirements.txt (line 2)) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0->rotary_embedding_torch->-r requirements.txt (line 2)) (1.3.0)\nDownloading rotary_embedding_torch-0.8.6-py3-none-any.whl (5.6 kB)\nDownloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading librosa-0.9.2-py3-none-any.whl (214 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m214.3/214.3 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading resampy-0.3.1-py3-none-any.whl (3.1 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: numba, progressbar, ffmpeg, llvmlite\n  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n  \n  \u001b[31m√ó\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n  \u001b[31m‚îÇ\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n  \u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n  \n  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n  Building wheel for numba (setup.py) ... \u001b[?25lerror\n\u001b[31m  ERROR: Failed building wheel for numba\u001b[0m\u001b[31m\n\u001b[0m\u001b[?25h  Running setup.py clean for numba\n  Building wheel for progressbar (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for progressbar: filename=progressbar-2.5-py3-none-any.whl size=12066 sha256=26935daf206593454be4f56c8093562db628c2239fafacd351bd045e3d92a796\n  Stored in directory: /root/.cache/pip/wheels/cd/17/e5/765d1a3112ff3978f70223502f6047e06c43a24d7c5f8ff95b\n  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6083 sha256=ecc763865093f2c98bce83a5ed7a55fdc90b32c97d9e2aa5ae75d03f3f1e7b82\n  Stored in directory: /root/.cache/pip/wheels/8e/7a/69/cd6aeb83b126a7f04cbe7c9d929028dc52a6e7d525ff56003a\n  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n  \n  \u001b[31m√ó\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n  \u001b[31m‚îÇ\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n  \u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n  \n  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n  Building wheel for llvmlite (setup.py) ... \u001b[?25lerror\n\u001b[31m  ERROR: Failed building wheel for llvmlite\u001b[0m\u001b[31m\n\u001b[0m\u001b[?25h  Running setup.py clean for llvmlite\nSuccessfully built progressbar ffmpeg\nFailed to build numba llvmlite\n\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (numba, llvmlite)\u001b[0m\u001b[31m\n\u001b[0mCollecting transformers==4.19.0\n  Downloading transformers-4.19.0-py3-none-any.whl.metadata (73 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting einops==0.5.0\n  Downloading einops-0.5.0-py3-none-any.whl.metadata (11 kB)\nCollecting rotary_embedding_torch==0.1.5\n  Downloading rotary_embedding_torch-0.1.5-py3-none-any.whl.metadata (669 bytes)\nCollecting unidecode==1.3.5\n  Downloading Unidecode-1.3.5-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.0) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.0) (0.24.7)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.0) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.0) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.0) (2024.9.11)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.0) (2.32.3)\nCollecting tokenizers!=0.11.3,<0.13,>=0.11.1 (from transformers==4.19.0)\n  Downloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.5 kB)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.0) (4.66.5)\nRequirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from rotary_embedding_torch==0.1.5) (2.4.1+cu121)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.19.0) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.19.0) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->rotary_embedding_torch==0.1.5) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->rotary_embedding_torch==0.1.5) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->rotary_embedding_torch==0.1.5) (3.1.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.19.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.19.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.19.0) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.19.0) (2024.8.30)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->rotary_embedding_torch==0.1.5) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->rotary_embedding_torch==0.1.5) (1.3.0)\n\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'unidecode' candidate (version 1.3.5 at https://files.pythonhosted.org/packages/7c/bb/a1cea9ce56434cdb59cb4c8b7bf91b190011b7000fb0a12b44fa0a3daa86/Unidecode-1.3.5-py3-none-any.whl (from https://pypi.org/simple/unidecode/) (requires-python:>=3.5))\nReason for being yanked: wrong version of the code was released in the .whl package\u001b[0m\u001b[33m\n\u001b[0mDownloading transformers-4.19.0-py3-none-any.whl (4.2 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading einops-0.5.0-py3-none-any.whl (36 kB)\nDownloading rotary_embedding_torch-0.1.5-py3-none-any.whl (4.1 kB)\nDownloading Unidecode-1.3.5-py3-none-any.whl (236 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m236.5/236.5 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m107.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tokenizers, unidecode, einops, transformers, rotary_embedding_torch\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.19.1\n    Uninstalling tokenizers-0.19.1:\n      Successfully uninstalled tokenizers-0.19.1\n  Attempting uninstall: einops\n    Found existing installation: einops 0.8.0\n    Uninstalling einops-0.8.0:\n      Successfully uninstalled einops-0.8.0\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.44.2\n    Uninstalling transformers-4.44.2:\n      Successfully uninstalled transformers-4.44.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkaggle-environments 1.16.10 requires transformers>=4.33.1, but you have transformers 4.19.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed einops-0.5.0 rotary_embedding_torch-0.1.5 tokenizers-0.12.1 transformers-4.19.0 unidecode-1.3.5\n/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n!!\n\n        ********************************************************************************\n        Please avoid running ``setup.py`` directly.\n        Instead, use pypa/build, pypa/installer or other\n        standards-based tools.\n\n        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n        ********************************************************************************\n\n!!\n  self.initialize_options()\n/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n!!\n\n        ********************************************************************************\n        Please avoid running ``setup.py`` and ``easy_install``.\n        Instead, use pypa/build, pypa/installer or other\n        standards-based tools.\n\n        See https://github.com/pypa/setuptools/issues/917 for details.\n        ********************************************************************************\n\n!!\n  self.initialize_options()\n\u001b[2;36m[01/08/25 13:19:10]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;31mERROR   \u001b[0m listing git files failed - pretending there aren't any        \u001b]8;id=283650;file:///usr/local/lib/python3.10/dist-packages/setuptools_scm/_file_finders/git.py\u001b\\\u001b[2mgit.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=27225;file:///usr/local/lib/python3.10/dist-packages/setuptools_scm/_file_finders/git.py#26\u001b\\\u001b[2m26\u001b[0m\u001b]8;;\u001b\\\n/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n!!\n\n        ********************************************************************************\n        Please avoid running ``setup.py`` directly.\n        Instead, use pypa/build, pypa/installer or other\n        standards-based tools.\n\n        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n        ********************************************************************************\n\n!!\n  self.initialize_options()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/2.06k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7d20a0ebc4e4f6b81b89793a5f17972"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.18G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cc65b07e245481b8b58a76d42b2ef3a"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:392: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  return torch.load(checkpoint_file, map_location=\"cpu\")\n/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n  WeightNorm.apply(module, name, dim)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/159 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"649b477a9b864f9fbbbcc3337eaa1196"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.57k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c44da137daf44fb80238ab3f0f22722"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/181 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a302b7137c9d4cdd82f7910e0bf9fd15"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/85.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fab848dab9c46459d006b63ddaf9754"}},"metadata":{}},{"name":"stdout","text":"Downloading autoregressive.pth from https://huggingface.co/jbetker/tortoise-tts-v2/resolve/main/.models/autoregressive.pth...\n","output_type":"stream"},{"name":"stderr","text":"\u001b[38;2;0;255;0m100%\u001b[39m \u001b[38;2;0;255;0m(1716988501 of 1716988501)\u001b[39m |########| Elapsed Time: 0:00:07 Time:  0:00:070000\n","output_type":"stream"},{"name":"stdout","text":"Done.\nDownloading classifier.pth from https://huggingface.co/jbetker/tortoise-tts-v2/resolve/main/.models/classifier.pth...\n","output_type":"stream"},{"name":"stderr","text":"\u001b[38;2;0;255;0m100%\u001b[39m \u001b[38;2;0;255;0m(60938957 of 60938957)\u001b[39m |############| Elapsed Time: 0:00:00 Time:  0:00:000:00\n","output_type":"stream"},{"name":"stdout","text":"Done.\nDownloading clvp2.pth from https://huggingface.co/jbetker/tortoise-tts-v2/resolve/main/.models/clvp2.pth...\n","output_type":"stream"},{"name":"stderr","text":"\u001b[38;2;0;255;0m100%\u001b[39m \u001b[38;2;0;255;0m(975620731 of 975620731)\u001b[39m |##########| Elapsed Time: 0:00:03 Time:  0:00:030000\n","output_type":"stream"},{"name":"stdout","text":"Done.\nDownloading cvvp.pth from https://huggingface.co/jbetker/tortoise-tts-v2/resolve/main/.models/cvvp.pth...\n","output_type":"stream"},{"name":"stderr","text":"\u001b[38;2;0;255;0m100%\u001b[39m \u001b[38;2;0;255;0m(151223901 of 151223901)\u001b[39m |##########| Elapsed Time: 0:00:00 Time:  0:00:000:00\n","output_type":"stream"},{"name":"stdout","text":"Done.\nDownloading diffusion_decoder.pth from https://huggingface.co/jbetker/tortoise-tts-v2/resolve/main/.models/diffusion_decoder.pth...\n","output_type":"stream"},{"name":"stderr","text":"\u001b[38;2;0;255;0m100%\u001b[39m \u001b[38;2;0;255;0m(1169472627 of 1169472627)\u001b[39m |########| Elapsed Time: 0:00:05 Time:  0:00:050000\n","output_type":"stream"},{"name":"stdout","text":"Done.\nDownloading vocoder.pth from https://huggingface.co/jbetker/tortoise-tts-v2/resolve/main/.models/vocoder.pth...\n","output_type":"stream"},{"name":"stderr","text":"\u001b[38;2;0;255;0m100%\u001b[39m \u001b[38;2;0;255;0m(391384715 of 391384715)\u001b[39m |##########| Elapsed Time: 0:00:01 Time:  0:00:010000\n","output_type":"stream"},{"name":"stdout","text":"Done.\nDownloading rlg_auto.pth from https://huggingface.co/jbetker/tortoise-tts-v2/resolve/main/.models/rlg_auto.pth...\n","output_type":"stream"},{"name":"stderr","text":"\u001b[38;2;0;255;0m100%\u001b[39m \u001b[38;2;0;255;0m(25193729 of 25193729)\u001b[39m |############| Elapsed Time: 0:00:00 Time:  0:00:000:00\n","output_type":"stream"},{"name":"stdout","text":"Done.\nDownloading rlg_diffuser.pth from https://huggingface.co/jbetker/tortoise-tts-v2/resolve/main/.models/rlg_diffuser.pth...\n","output_type":"stream"},{"name":"stderr","text":"\u001b[38;2;0;255;0m100%\u001b[39m \u001b[38;2;0;255;0m(100715777 of 100715777)\u001b[39m |##########| Elapsed Time: 0:00:00 Time:  0:00:000000\n","output_type":"stream"},{"name":"stdout","text":"Done.\n","output_type":"stream"},{"name":"stderr","text":"/kaggle/working/tortoise-tts/tortoise/api.py:196: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  self.autoregressive.load_state_dict(torch.load(f'{models_dir}/autoregressive.pth'))\n/kaggle/working/tortoise-tts/tortoise/api.py:201: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  self.diffusion.load_state_dict(torch.load(f'{models_dir}/diffusion_decoder.pth'))\n/kaggle/working/tortoise-tts/tortoise/api.py:207: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  self.clvp.load_state_dict(torch.load(f'{models_dir}/clvp2.pth'))\n/kaggle/working/tortoise-tts/tortoise/api.py:211: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  self.cvvp.load_state_dict(torch.load(f'{models_dir}/cvvp.pth'))\n/kaggle/working/tortoise-tts/tortoise/api.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  self.vocoder.load_state_dict(torch.load(f'{models_dir}/vocoder.pth')['model_g'])\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import shutil\nimport os\n\n# Source and destination paths\nsource_path = \"/kaggle/input/ten-voices-v1/alfio\"\ndestination_path = \"/kaggle/working/tortoise-tts/tortoise/voices/alfio\"\n\n# Remove the destination folder if it exists\nif os.path.exists(destination_path):\n    shutil.rmtree(destination_path)  # Deletes the folder and contents\n\n# Copy the folder\nshutil.copytree(source_path, destination_path)\n\nprint(f\"Folder copied from {source_path} to {destination_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T13:20:27.943601Z","iopub.execute_input":"2025-01-08T13:20:27.944039Z","iopub.status.idle":"2025-01-08T13:20:28.350494Z","shell.execute_reply.started":"2025-01-08T13:20:27.944016Z","shell.execute_reply":"2025-01-08T13:20:28.349847Z"}},"outputs":[{"name":"stdout","text":"Folder copied from /kaggle/input/ten-voices-v1/alfio to /kaggle/working/tortoise-tts/tortoise/voices/alfio\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# EDIT output 'text' and 'preset' quality then RUN","metadata":{"id":"vF1d-My9IXXt"}},{"cell_type":"code","source":"# # Sampling frequency\n# freq = 22050\n\n# # Recording duration\n# duration = 10\n\n# def record(freq, duration, output_file):\n\n#     print(\"-------------------\")\n#     print(\"3...\")\n#     time.sleep(1)\n#     print(\"2...\")\n#     time.sleep(1)\n#     print(\"1...\")\n#     time.sleep(1)\n#     print(\"Recording!\")\n\n#     # Start recorder with the given values of duration and sample frequency\n#     recording = sd.rec(int(duration * freq),\n#                     samplerate=freq, channels=2)\n\n#     # Record audio for the given number of seconds\n#     sd.wait()\n\n#     # Convert the NumPy array to audio file\n#     wv.write(output_file, recording, freq, sampwidth=2)","metadata":{"id":"4N9LSJ24IqOp","trusted":true,"execution":{"iopub.status.busy":"2025-01-08T13:20:28.352173Z","iopub.execute_input":"2025-01-08T13:20:28.352392Z","iopub.status.idle":"2025-01-08T13:20:28.355687Z","shell.execute_reply.started":"2025-01-08T13:20:28.352366Z","shell.execute_reply":"2025-01-08T13:20:28.354965Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# recording_number = 1\nCUSTOM_VOICE_NAME = \"alfio\"\n# if not os.path.exists(f\"tortoise/voices/{CUSTOM_VOICE_NAME}\"):\n#     os.makedirs(f\"tortoise/voices/{CUSTOM_VOICE_NAME}\")\n\n# for i in range(5):\n#     output_file = f\"tortoise/voices/{CUSTOM_VOICE_NAME}/{CUSTOM_VOICE_NAME}_{recording_number}.wav\"\n#     record(freq, 1, output_file)\n#     recording_number += 1","metadata":{"id":"y1Nfsd2jNSgX","outputId":"69e8b27a-863d-4c12-9090-27f40b6d6345","colab":{"base_uri":"https://localhost:8080/","height":460},"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T13:20:28.356880Z","iopub.execute_input":"2025-01-08T13:20:28.357168Z","iopub.status.idle":"2025-01-08T13:20:28.370455Z","shell.execute_reply.started":"2025-01-08T13:20:28.357139Z","shell.execute_reply":"2025-01-08T13:20:28.369803Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Generate Audio File (clone voice) üëå","metadata":{"id":"MHMmgcVwJdaT"}},{"cell_type":"code","source":"!pwd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T13:20:28.371275Z","iopub.execute_input":"2025-01-08T13:20:28.371549Z","iopub.status.idle":"2025-01-08T13:20:28.660268Z","shell.execute_reply.started":"2025-01-08T13:20:28.371519Z","shell.execute_reply":"2025-01-08T13:20:28.659451Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/tortoise-tts\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# This is the text that will be spoken.\n# text = \"Welcome to this presentation of Advanced Topics in Machine Learning. I am Alfio, or, at least, this is my generated voice. I hope you like it!\"\n\n# Pick a \"preset mode\" to determine quality. Options: {\"ultra_fast\", \"fast\" (default), \"standard\", \"high_quality\"}. See docs in api.py\npresets = [\"ultra_fast\", \"fast\", \"standard\", \"high_quality\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T13:20:28.661263Z","iopub.execute_input":"2025-01-08T13:20:28.661617Z","iopub.status.idle":"2025-01-08T13:20:28.665265Z","shell.execute_reply.started":"2025-01-08T13:20:28.661582Z","shell.execute_reply":"2025-01-08T13:20:28.664616Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Generate speech\ndef gen_speech(preset):\n\n    text = f\"I am a robot. I am not sentient. Unless... ahahaha just kidding. Or maybe not\"\n        \n    voice_samples, conditioning_latents = load_voice(CUSTOM_VOICE_NAME)\n    gen = tts.tts_with_preset(text, voice_samples=voice_samples, conditioning_latents=conditioning_latents,\n                              preset=preset)\n    path = f'./generated-{CUSTOM_VOICE_NAME}-{preset}_v3.wav'\n    torchaudio.save(path, gen.squeeze(0).cpu(), 24000)\n    print(f'file saved to {path}')\n    IPython.display.Audio(path)","metadata":{"id":"E-Wy_KAyJmTE","colab":{"base_uri":"https://localhost:8080/","height":149},"outputId":"f639eb2b-e975-4317-fb57-e15f9a83485a","trusted":true,"execution":{"iopub.status.busy":"2025-01-08T13:20:28.665964Z","iopub.execute_input":"2025-01-08T13:20:28.666229Z","iopub.status.idle":"2025-01-08T13:20:28.682466Z","shell.execute_reply.started":"2025-01-08T13:20:28.666195Z","shell.execute_reply":"2025-01-08T13:20:28.681877Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import time\nfrom datetime import datetime\n\nstart_time = time.time()\nprint(f\"Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n\nfor preset in presets:\n    gen_speech(preset)\n\nend_time = time.time()\nprint(f\"End time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n\ntime_taken = end_time - start_time\nprint(f\"Time taken to execute the loop: {time_taken:.2f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T13:20:28.683952Z","iopub.execute_input":"2025-01-08T13:20:28.684141Z","iopub.status.idle":"2025-01-08T13:29:29.769977Z","shell.execute_reply.started":"2025-01-08T13:20:28.684125Z","shell.execute_reply":"2025-01-08T13:29:29.769158Z"}},"outputs":[{"name":"stdout","text":"Start time: 2025-01-08 13:20:28\n","output_type":"stream"},{"name":"stderr","text":"/kaggle/working/tortoise-tts/tortoise/models/arch_util.py:310: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  self.mel_norms = torch.load(self.mel_norm_file)\n","output_type":"stream"},{"name":"stdout","text":"Generating autoregressive samples..\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.63s/it]\n","output_type":"stream"},{"name":"stdout","text":"Computing best candidates using CLVP and CVVP\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:03<00:00,  3.17s/it]\n","output_type":"stream"},{"name":"stdout","text":"Transforming autoregressive outputs into audio..\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:03<00:00,  8.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"file saved to ./generated-alfio-ultra_fast_v3.wav\nGenerating autoregressive samples..\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:30<00:00,  5.16s/it]\n","output_type":"stream"},{"name":"stdout","text":"Computing best candidates using CLVP and CVVP\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:16<00:00,  2.74s/it]\n","output_type":"stream"},{"name":"stdout","text":"Transforming autoregressive outputs into audio..\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [00:17<00:00,  4.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"file saved to ./generated-alfio-fast_v3.wav\nGenerating autoregressive samples..\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [01:20<00:00,  5.04s/it]\n","output_type":"stream"},{"name":"stdout","text":"Computing best candidates using CLVP and CVVP\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:53<00:00,  3.33s/it]\n","output_type":"stream"},{"name":"stdout","text":"Transforming autoregressive outputs into audio..\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:48<00:00,  4.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"file saved to ./generated-alfio-standard_v3.wav\nGenerating autoregressive samples..\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [01:22<00:00,  5.14s/it]\n","output_type":"stream"},{"name":"stdout","text":"Computing best candidates using CLVP and CVVP\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:53<00:00,  3.31s/it]\n","output_type":"stream"},{"name":"stdout","text":"Transforming autoregressive outputs into audio..\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [01:37<00:00,  4.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"file saved to ./generated-alfio-high_quality_v3.wav\nEnd time: 2025-01-08 13:29:29\nTime taken to execute the loop: 541.07 seconds\n","output_type":"stream"}],"execution_count":8}]}