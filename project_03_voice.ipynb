{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voice cloning tool\n",
    "\n",
    "### For GPU reasons, only run this notebook on Kaggle or with a dedicated GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OvQqgdXMINpN"
   },
   "source": [
    "## Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-08T13:18:13.903696Z",
     "iopub.status.busy": "2025-01-08T13:18:13.903355Z",
     "iopub.status.idle": "2025-01-08T13:20:27.942423Z",
     "shell.execute_reply": "2025-01-08T13:20:27.941577Z",
     "shell.execute_reply.started": "2025-01-08T13:18:13.903669Z"
    },
    "id": "uC2qGJ0nITKW",
    "outputId": "d03d1e15-91da-4ca6-ca62-2a1508877351",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!sudo apt install portaudio19-dev\n",
    "!pip3 install -U scipy\n",
    "!pip3 install wavio\n",
    "!pip3 install sounddevice\n",
    "\n",
    "!git clone https://github.com/jnordberg/tortoise-tts.git\n",
    "%cd tortoise-tts\n",
    "!pip3 install -r requirements.txt\n",
    "!pip3 install transformers==4.19.0 einops==0.5.0 rotary_embedding_torch==0.1.5 unidecode==1.3.5\n",
    "!python3 setup.py install\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import IPython\n",
    "\n",
    "from tortoise.api import TextToSpeech\n",
    "from tortoise.utils.audio import load_audio, load_voice, load_voices\n",
    "\n",
    "tts = TextToSpeech()\n",
    "\n",
    "import os\n",
    "from google.colab import files\n",
    "\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "import wavio as wv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T13:20:27.944039Z",
     "iopub.status.busy": "2025-01-08T13:20:27.943601Z",
     "iopub.status.idle": "2025-01-08T13:20:28.350494Z",
     "shell.execute_reply": "2025-01-08T13:20:28.349847Z",
     "shell.execute_reply.started": "2025-01-08T13:20:27.944016Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder copied from /kaggle/input/ten-voices-v1/alfio to /kaggle/working/tortoise-tts/tortoise/voices/alfio\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Source and destination paths\n",
    "source_path = \"/kaggle/input/ten-voices-v1/alfio\"\n",
    "destination_path = \"/kaggle/working/tortoise-tts/tortoise/voices/alfio\"\n",
    "\n",
    "# Remove the destination folder if it exists\n",
    "if os.path.exists(destination_path):\n",
    "    shutil.rmtree(destination_path)  # Deletes the folder and contents\n",
    "\n",
    "# Copy the folder\n",
    "shutil.copytree(source_path, destination_path)\n",
    "\n",
    "print(f\"Folder copied from {source_path} to {destination_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MHMmgcVwJdaT"
   },
   "source": [
    "# Generate Audio File (clone voice) ðŸ‘Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T13:20:28.371549Z",
     "iopub.status.busy": "2025-01-08T13:20:28.371275Z",
     "iopub.status.idle": "2025-01-08T13:20:28.660268Z",
     "shell.execute_reply": "2025-01-08T13:20:28.659451Z",
     "shell.execute_reply.started": "2025-01-08T13:20:28.371519Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/tortoise-tts\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T13:20:28.661617Z",
     "iopub.status.busy": "2025-01-08T13:20:28.661263Z",
     "iopub.status.idle": "2025-01-08T13:20:28.665265Z",
     "shell.execute_reply": "2025-01-08T13:20:28.664616Z",
     "shell.execute_reply.started": "2025-01-08T13:20:28.661582Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Pick a \"preset mode\" to determine quality. Options: {\"ultra_fast\", \"fast\" (default), \"standard\", \"high_quality\"}. See docs in api.py\n",
    "presets = [\"ultra_fast\", \"fast\", \"standard\", \"high_quality\"]\n",
    "CUSTOM_VOICE_NAME = \"alfio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149
    },
    "execution": {
     "iopub.execute_input": "2025-01-08T13:20:28.666229Z",
     "iopub.status.busy": "2025-01-08T13:20:28.665964Z",
     "iopub.status.idle": "2025-01-08T13:20:28.682466Z",
     "shell.execute_reply": "2025-01-08T13:20:28.681877Z",
     "shell.execute_reply.started": "2025-01-08T13:20:28.666195Z"
    },
    "id": "E-Wy_KAyJmTE",
    "outputId": "f639eb2b-e975-4317-fb57-e15f9a83485a",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Generate speech\n",
    "def gen_speech(preset):\n",
    "\n",
    "    text = f\"I am a robot. I am not sentient. Unless... ahahaha just kidding. Or maybe not\"\n",
    "        \n",
    "    voice_samples, conditioning_latents = load_voice(CUSTOM_VOICE_NAME)\n",
    "    gen = tts.tts_with_preset(text, voice_samples=voice_samples, conditioning_latents=conditioning_latents,\n",
    "                              preset=preset)\n",
    "    path = f'./generated-{CUSTOM_VOICE_NAME}-{preset}_v3.wav'\n",
    "    torchaudio.save(path, gen.squeeze(0).cpu(), 24000)\n",
    "    print(f'file saved to {path}')\n",
    "    IPython.display.Audio(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T13:20:28.684141Z",
     "iopub.status.busy": "2025-01-08T13:20:28.683952Z",
     "iopub.status.idle": "2025-01-08T13:29:29.769977Z",
     "shell.execute_reply": "2025-01-08T13:29:29.769158Z",
     "shell.execute_reply.started": "2025-01-08T13:20:28.684125Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2025-01-08 13:20:28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/tortoise-tts/tortoise/models/arch_util.py:310: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.mel_norms = torch.load(self.mel_norm_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP and CVVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:03<00:00,  8.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to ./generated-alfio-ultra_fast_v3.wav\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:30<00:00,  5.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP and CVVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:16<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:17<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to ./generated-alfio-fast_v3.wav\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [01:20<00:00,  5.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP and CVVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:53<00:00,  3.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:48<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to ./generated-alfio-standard_v3.wav\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [01:22<00:00,  5.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP and CVVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:53<00:00,  3.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 400/400 [01:37<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to ./generated-alfio-high_quality_v3.wav\n",
      "End time: 2025-01-08 13:29:29\n",
      "Time taken to execute the loop: 541.07 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "start_time = time.time()\n",
    "print(f\"Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# Compare the different presets\n",
    "for preset in presets:\n",
    "    gen_speech(preset)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"End time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "time_taken = end_time - start_time\n",
    "print(f\"Time taken to execute the loop: {time_taken:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "OvQqgdXMINpN",
    "vF1d-My9IXXt",
    "MHMmgcVwJdaT"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6445856,
     "sourceId": 10402552,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6446100,
     "sourceId": 10402860,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
